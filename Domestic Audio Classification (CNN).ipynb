{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:\\SINS dataset\n"
     ]
    }
   ],
   "source": [
    "%cd H:/SINS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import cv2\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# constants\n",
    "img_folder = 'img2'\n",
    "img_name = ['_pressure.png', '_spec1.png', '_spec2.png', '_spec3.png']\n",
    "\n",
    "im_size = 64\n",
    "im_size_flat = im_size * im_size\n",
    "n_labels = 9\n",
    "n_channels = 1 # grayscale\n",
    "sd = np.sqrt(2) / np.sqrt(im_size_flat)\n",
    "\n",
    "req_improve = 500\n",
    "update_cnt = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "n_folds = 4\n",
    "\n",
    "# layer vars\n",
    "# conv1 (32 * 5x5, 2x2 pool) -> conv2 (64 * 5x5, 2x2 pool) -> fully connected (1024 nodes) -> fully connected (output)\n",
    "# filter_size_1 = 5\n",
    "# n_filters_1 = 32\n",
    "\n",
    "# filter_size_2 = 5\n",
    "# n_filters_2 = 64\n",
    "\n",
    "# fc_size = 1024\n",
    "\n",
    "# allow for procedurally-generated cnns\n",
    "# format layer_id: {layer_parameter_id: parameter ... etc}\n",
    "layer_vars = [\n",
    "    ['conv', {'filter_size': 3, 'n_filters': 16}],\n",
    "    ['relu', {}],\n",
    "    ['conv', {'filter_size': 5, 'n_filters': 32}],\n",
    "    ['relu', {}],\n",
    "    ['pool', {'ksize': 2, 'strides': 2}],\n",
    "    ['conv', {'filter_size': 5, 'n_filters': 32}],\n",
    "    ['relu', {}],\n",
    "    ['pool', {'ksize': 2, 'strides': 2}],\n",
    "    ['flat', {}],\n",
    "    ['full', {'n_outputs': 2500}],\n",
    "    ['relu', {}],\n",
    "    ['full', {'n_outputs': n_labels}],\n",
    "]\n",
    "\n",
    "# learning vars\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(index, do_all = False, spec_fold = 0, epochs = 50, train_batch = 50, test_batch = 50, verbose = True, save_model = False, name = \"default\"):\n",
    "    random.seed(seed)\n",
    "#     tf.set_random_seed(seed)\n",
    "    folds = get_folds(index)\n",
    "    if do_all:\n",
    "        tl_acc = tl_f1 = 0\n",
    "        for f in range(n_folds):\n",
    "            trX, trY, tX, tY = get_sets(folds, f)\n",
    "            acc, f1 = train_test(trX, trY, tX, tY, epochs, train_batch, test_batch, verbose)\n",
    "            tl_acc += acc\n",
    "            tl_f1 += f1\n",
    "        print(\"{}-fold cross validation. Average accuracy: {:.4%}. Average F1: {:.4%}\".format(n_folds, tl_acc/n_folds, tl_f1/n_folds))\n",
    "            \n",
    "    else:\n",
    "        trX, trY, tX, tY = get_sets(folds, spec_fold)\n",
    "        train_test(trX, trY, tX, tY, epochs, train_batch, test_batch, verbose, save_model, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folds(index):\n",
    "    afs, labels, _ = zip(*[line.rstrip('\\n').split('\\t') for line in open('meta.txt').readlines()])\n",
    "    afs_imlinks = [img_folder + af[5:-4] + img_name[index] for af in afs]\n",
    "        \n",
    "    # get smallest no. of classes\n",
    "    mincnt = Counter(labels).most_common()[-1][1]\n",
    "    \n",
    "    afs_label_sep = {}\n",
    "    for (af, label) in zip(afs_imlinks, labels):\n",
    "        if label in afs_label_sep:\n",
    "            afs_label_sep[label].append(af)\n",
    "        else:\n",
    "            afs_label_sep[label] = [af]\n",
    "\n",
    "    afs_label_sep_sampled = {label:random.sample(afs_label_sep[label], mincnt) for label in afs_label_sep.keys()}\n",
    "\n",
    "    # partition the graph into n_folds partitions for cross-validation\n",
    "    folds = {fold+1:[] for fold in range(n_folds)}\n",
    "    samples = int(math.ceil(mincnt / n_folds))\n",
    "\n",
    "    for label in afs_label_sep_sampled.keys():\n",
    "        random.shuffle(afs_label_sep_sampled[label])\n",
    "        for fold in range(n_folds):\n",
    "            folds[fold+1] += [(af, label) for af in afs_label_sep_sampled[label][fold*samples:(fold+1)*samples]]\n",
    "\n",
    "    return list(folds.values())\n",
    "\n",
    "# 0-indexed get training/testing sets\n",
    "def get_sets(folds, fold = -1):\n",
    "    _, labels, _ = zip(*[line.rstrip('\\n').split('\\t') for line in open('meta.txt').readlines()])\n",
    "    sces = set(labels)\n",
    "    sce_int_map = {sce:i+1 for i, sce in enumerate(sces)}\n",
    "    int_sce_map = {sce_int_map[i]:i for i in sce_int_map.keys()}\n",
    "\n",
    "    ex_fold = folds[fold]\n",
    "    ot_fold = folds[0:fold] + folds[fold+1:]\n",
    "    chainfold = list(chain.from_iterable(ot_fold))\n",
    "    random.shuffle(chainfold)\n",
    "    trX, trY = zip(*[(af, label) for (af, label) in chainfold])\n",
    "    tX, tY = zip(*[(af, label) for (af, label) in ex_fold])\n",
    "    \n",
    "    trY = np.array([[1 if int_sce_map[c+1] == label else 0 for c in range(len(sces))] for label in trY])\n",
    "    tY = np.array([[1 if int_sce_map[c+1] == label else 0 for c in range(len(sces))] for label in tY])\n",
    "    \n",
    "    return (trX, trY, tX, tY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to initialise weights and biases\n",
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev = sd, seed = seed))\n",
    "\n",
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.0, shape = [length]))\n",
    "\n",
    "def flatten_layer(layer):\n",
    "    layer_shape = layer.get_shape()\n",
    "    n_features = np.array(layer_shape[1:4], dtype=int).prod()\n",
    "    layer_flat = tf.reshape(layer, [-1, n_features])\n",
    "    return layer_flat, n_features\n",
    "\n",
    "# helper functions to define the layers\n",
    "def new_conv_layer(input_data, n_channels, filter_size, n_filters, strides = 1):\n",
    "    shape = [filter_size, filter_size, n_channels, n_filters]\n",
    "    weights = new_weights(shape)\n",
    "    biases = new_biases(n_filters)\n",
    "    \n",
    "    layer = tf.nn.conv2d(input_data, weights, strides = [1, strides, strides, 1], padding = 'SAME')\n",
    "    layer += biases\n",
    "    \n",
    "    return layer, weights\n",
    "\n",
    "def new_relu_layer(layer):\n",
    "    return tf.nn.relu(layer)\n",
    "\n",
    "def new_pool_layer(input_data, ksize = 2, strides = 2):\n",
    "    return tf.nn.max_pool(input_data, ksize = [1, ksize, ksize, 1], strides = [1, strides, strides, 1], padding = 'SAME')\n",
    "\n",
    "def new_fc_layer(input_data, n_inputs, n_outputs):\n",
    "    weights = new_weights([n_inputs, n_outputs])\n",
    "    biases = new_biases(n_outputs)\n",
    "    \n",
    "    layer = tf.matmul(input_data, weights) + biases\n",
    "    \n",
    "    return layer\n",
    "\n",
    "# helper function to get images\n",
    "def get_ims(links):\n",
    "    return np.array([(1 - cv2.imread(link, 0)/255).reshape(im_size * im_size) for link in links])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(xtrain, ytrain, xtest, ytest, epochs = 50, train_batch = 50, test_batch = 50, verbose = True, save_model = False, name = \"default\"):\n",
    "    # tensorflow placeholder vars\n",
    "    tfX = tf.placeholder(tf.float32, [None, im_size * im_size], name = 'tfX')\n",
    "    x_image = tf.reshape(tfX, [-1, im_size, im_size, n_channels])\n",
    "\n",
    "    y_true = tf.placeholder(tf.float32, [None, n_labels], name = 'y_true')\n",
    "    y_true_cls = tf.argmax(y_true, axis = 1)\n",
    "    \n",
    "    # build cnn\n",
    "    # first layer\n",
    "    next_in = 0\n",
    "    l_id, param = layer_vars[0]\n",
    "    if l_id == 'pool':\n",
    "        layer = new_pool_layer(x_image, **param)\n",
    "    if l_id == 'conv':\n",
    "        layer, w1 = new_conv_layer(x_image, n_channels, **param)\n",
    "        next_in = param['n_filters']\n",
    "    if l_id == 'relu':\n",
    "        layer = new_relu_layer(x_image)\n",
    "    if l_id == 'flat':\n",
    "        layer, next_in = flatten_layer(x_image)\n",
    "    if l_id == 'full':\n",
    "        print(\"Error: Cannot start with a fully-connected layer without first flattening the image.\")\n",
    "        return\n",
    "\n",
    "    # subsequent layers\n",
    "    for (l_id, param) in layer_vars[1:]:\n",
    "        if l_id == 'pool':\n",
    "            layer = new_pool_layer(layer)\n",
    "            \n",
    "        if l_id == 'conv':\n",
    "            layer, _ = new_conv_layer(layer, next_in, **param)\n",
    "            next_in = param['n_filters']\n",
    "            \n",
    "        if l_id == 'relu':\n",
    "            layer = new_relu_layer(layer)\n",
    "            \n",
    "        if l_id == 'flat':\n",
    "            layer, next_in = flatten_layer(layer)\n",
    "            \n",
    "        if l_id == 'full':\n",
    "            layer = new_fc_layer(layer, next_in, **param)\n",
    "            next_in = param['n_outputs']\n",
    "            \n",
    "\n",
    "    y_pred = tf.nn.softmax(layer)\n",
    "    y_pred_cls = tf.argmax(y_pred, axis = 1)\n",
    "\n",
    "\n",
    "    # cost function and optimiser\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits = layer, labels = y_true)\n",
    "    cost = tf.reduce_mean(cross_entropy)\n",
    "    optimiser = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "    correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "       \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # saving vars\n",
    "        if save_model:\n",
    "            saver = tf.train.Saver()\n",
    "            save_dir = 'checkpoints/'\n",
    "            save_path = os.path.join(save_dir, 'best_val'+name)\n",
    "            best_loss = 10000.0\n",
    "            last_improvement = 0\n",
    "        \n",
    "        # training\n",
    "        for i in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            index = 0\n",
    "            while index < len(xtrain):\n",
    "                x_batch_links = xtrain[index:index + train_batch]\n",
    "                y_true_batch = ytrain[index:index + train_batch]\n",
    "                x_batch = get_ims(x_batch_links)\n",
    "                \n",
    "                feed_dict_train = {tfX: x_batch, y_true: y_true_batch}\n",
    "                _, c = sess.run([optimiser, cost], feed_dict = feed_dict_train)\n",
    "                epoch_loss += c\n",
    "                index += train_batch\n",
    "                \n",
    "                if verbose:\n",
    "                    if index % 1000 == 0:\n",
    "                        acc = sess.run(accuracy, feed_dict = feed_dict_train)\n",
    "                        print(\"{:.0%} complete. Training accuracy: {:.4%}\".format(index / len(xtrain), acc))\n",
    "                        \n",
    "            if save_model and (i % 3 == 0 or i==epochs-1):\n",
    "                if best_loss > epoch_loss:\n",
    "                    print(\"Improvement found\")\n",
    "                    best_loss = epoch_loss\n",
    "                    last_improvement = i\n",
    "                    saver.save(sess = sess, save_path = save_path)\n",
    "                    \n",
    "            if verbose or i % 5 == 0:\n",
    "                print(\"Epoch {} completed out of {}. Loss: {}\".format(i+1, epochs, epoch_loss))\n",
    "            \n",
    "            if save_model:\n",
    "                if i - last_improvement > req_improve:\n",
    "                    print(\"No improvements found in the last {} epochs. Stopping optimisation.\".format(req_improve))\n",
    "                    break\n",
    "        \n",
    "        # testing\n",
    "        n_test = len(xtest)\n",
    "        cls_pred = np.zeros(shape = n_test, dtype = np.int)\n",
    "        \n",
    "        index = 0\n",
    "        while index < n_test:\n",
    "            x_batch_links = xtest[index:index + test_batch]\n",
    "            y_true_batch = ytest[index: index + test_batch]\n",
    "            x_batch = get_ims(x_batch_links)\n",
    "            \n",
    "            feed_dict_test = {tfX: x_batch, y_true: y_true_batch}\n",
    "            cls_pred[index:index + test_batch] = sess.run(y_pred_cls, feed_dict = feed_dict_test)\n",
    "            index += test_batch\n",
    "        cls_true = sess.run(tf.argmax(ytest, axis = 1))\n",
    "        correct = (cls_true == cls_pred)\n",
    "        acc = correct.sum() / n_test\n",
    "        f1 = f1_score(cls_true, cls_pred, average = 'macro')\n",
    "    \n",
    "        print(\"Accuracy on Test-Set: {0:.4%} ({1} / {2}). F1 score: {3:.4%}.\".format(acc, correct.sum(), n_test, f1))\n",
    "        return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15% complete. Training accuracy: 44.0000%\n",
      "30% complete. Training accuracy: 50.0000%\n",
      "46% complete. Training accuracy: 54.0000%\n",
      "61% complete. Training accuracy: 36.0000%\n",
      "76% complete. Training accuracy: 56.0000%\n",
      "91% complete. Training accuracy: 44.0000%\n",
      "Epoch 1 completed out of 2. Loss: 199.1177077293396\n",
      "15% complete. Training accuracy: 50.0000%\n",
      "30% complete. Training accuracy: 60.0000%\n",
      "46% complete. Training accuracy: 60.0000%\n",
      "61% complete. Training accuracy: 46.0000%\n",
      "76% complete. Training accuracy: 66.0000%\n",
      "91% complete. Training accuracy: 48.0000%\n",
      "Epoch 2 completed out of 2. Loss: 165.06072610616684\n",
      "Accuracy on Test-Set: 51.8519% (1134 / 2187). F1 score: 49.4362%.\n",
      "15% complete. Training accuracy: 10.0000%\n",
      "30% complete. Training accuracy: 12.0000%\n",
      "46% complete. Training accuracy: 14.0000%\n",
      "61% complete. Training accuracy: 26.0000%\n",
      "76% complete. Training accuracy: 26.0000%\n",
      "91% complete. Training accuracy: 40.0000%\n",
      "Epoch 1 completed out of 2. Loss: 261.8935272693634\n",
      "15% complete. Training accuracy: 42.0000%\n",
      "30% complete. Training accuracy: 52.0000%\n",
      "46% complete. Training accuracy: 50.0000%\n",
      "61% complete. Training accuracy: 42.0000%\n",
      "76% complete. Training accuracy: 46.0000%\n",
      "91% complete. Training accuracy: 48.0000%\n",
      "Epoch 2 completed out of 2. Loss: 168.92861944437027\n",
      "Accuracy on Test-Set: 55.0983% (1205 / 2187). F1 score: 54.0295%.\n",
      "15% complete. Training accuracy: 50.0000%\n",
      "30% complete. Training accuracy: 54.0000%\n",
      "46% complete. Training accuracy: 66.0000%\n",
      "61% complete. Training accuracy: 58.0000%\n",
      "76% complete. Training accuracy: 70.0000%\n",
      "91% complete. Training accuracy: 60.0000%\n",
      "Epoch 1 completed out of 2. Loss: 151.6337444782257\n",
      "15% complete. Training accuracy: 76.0000%\n",
      "30% complete. Training accuracy: 72.0000%\n",
      "46% complete. Training accuracy: 76.0000%\n",
      "61% complete. Training accuracy: 76.0000%\n",
      "76% complete. Training accuracy: 78.0000%\n",
      "91% complete. Training accuracy: 78.0000%\n",
      "Epoch 2 completed out of 2. Loss: 89.26674100756645\n",
      "Accuracy on Test-Set: 75.7659% (1657 / 2187). F1 score: 75.7883%.\n",
      "15% complete. Training accuracy: 22.0000%\n",
      "30% complete. Training accuracy: 52.0000%\n",
      "46% complete. Training accuracy: 52.0000%\n",
      "61% complete. Training accuracy: 36.0000%\n",
      "76% complete. Training accuracy: 54.0000%\n",
      "91% complete. Training accuracy: 42.0000%\n",
      "Epoch 1 completed out of 2. Loss: 195.73581194877625\n",
      "15% complete. Training accuracy: 72.0000%\n",
      "30% complete. Training accuracy: 72.0000%\n",
      "46% complete. Training accuracy: 74.0000%\n",
      "61% complete. Training accuracy: 74.0000%\n",
      "76% complete. Training accuracy: 78.0000%\n",
      "91% complete. Training accuracy: 64.0000%\n",
      "Epoch 2 completed out of 2. Loss: 116.59283924102783\n",
      "Accuracy on Test-Set: 75.5373% (1652 / 2187). F1 score: 74.8101%.\n"
     ]
    }
   ],
   "source": [
    "cnn(0, epochs = 2)\n",
    "cnn(1, epochs = 2)\n",
    "cnn(2, epochs = 2)\n",
    "cnn(3, epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement found\n",
      "Epoch 1 completed out of 500. Loss: 195.73581194877625\n",
      "Improvement found\n",
      "Epoch 6 completed out of 500. Loss: 49.81787860393524\n",
      "Improvement found\n",
      "Improvement found\n",
      "Epoch 11 completed out of 500. Loss: 23.72707566898316\n",
      "Improvement found\n",
      "Improvement found\n",
      "Epoch 16 completed out of 500. Loss: 12.072815595194697\n",
      "Improvement found\n",
      "Epoch 21 completed out of 500. Loss: 6.519338534624694\n",
      "Improvement found\n",
      "Improvement found\n",
      "Epoch 26 completed out of 500. Loss: 5.027654196041112\n",
      "Improvement found\n",
      "Epoch 31 completed out of 500. Loss: 1.3042422788036987\n",
      "Improvement found\n",
      "Epoch 36 completed out of 500. Loss: 0.48787882811686245\n",
      "Epoch 41 completed out of 500. Loss: 5.046820111710261\n",
      "Epoch 46 completed out of 500. Loss: 5.053301744102953\n",
      "Epoch 51 completed out of 500. Loss: 0.4746635504582599\n",
      "Improvement found\n",
      "Epoch 56 completed out of 500. Loss: 0.46570907641583403\n",
      "Improvement found\n",
      "Improvement found\n",
      "Epoch 61 completed out of 500. Loss: 0.2662339185503697\n",
      "Improvement found\n",
      "Epoch 66 completed out of 500. Loss: 0.19121827316990903\n",
      "Improvement found\n",
      "Improvement found\n",
      "Epoch 71 completed out of 500. Loss: 0.16378956282289892\n",
      "Epoch 76 completed out of 500. Loss: 3.7585691663734906\n",
      "Epoch 81 completed out of 500. Loss: 0.19373066678020745\n",
      "Improvement found\n",
      "Epoch 86 completed out of 500. Loss: 0.1615288012486742\n",
      "Improvement found\n",
      "Improvement found\n",
      "Epoch 91 completed out of 500. Loss: 0.14216826344603373\n",
      "Improvement found\n",
      "Epoch 96 completed out of 500. Loss: 0.1286893918640999\n",
      "Improvement found\n",
      "Epoch 101 completed out of 500. Loss: 0.10848372518285032\n",
      "Improvement found\n",
      "Improvement found\n",
      "Epoch 106 completed out of 500. Loss: 0.09321054660267691\n",
      "Improvement found\n",
      "Epoch 111 completed out of 500. Loss: 0.08447098474835002\n",
      "Improvement found\n",
      "Epoch 116 completed out of 500. Loss: 15.557927156724872\n",
      "Epoch 121 completed out of 500. Loss: 0.23030047394857434\n",
      "Epoch 126 completed out of 500. Loss: 0.1127187331472328\n",
      "Epoch 131 completed out of 500. Loss: 0.10309909977308962\n",
      "Epoch 136 completed out of 500. Loss: 0.09838882224198642\n",
      "Epoch 141 completed out of 500. Loss: 0.08751608386211274\n",
      "Epoch 146 completed out of 500. Loss: 0.091956602101817\n",
      "Improvement found\n",
      "Improvement found\n",
      "Epoch 151 completed out of 500. Loss: 0.07518639407338412\n",
      "Epoch 156 completed out of 500. Loss: 0.09096188275049144\n",
      "Epoch 161 completed out of 500. Loss: 4.586417454011098\n",
      "Epoch 166 completed out of 500. Loss: 0.09521341351414492\n",
      "Epoch 171 completed out of 500. Loss: 0.08361927597719898\n",
      "Epoch 176 completed out of 500. Loss: 0.08341716544910582\n",
      "Epoch 181 completed out of 500. Loss: 0.07779777615124317\n",
      "Epoch 186 completed out of 500. Loss: 0.07603864263103333\n",
      "Improvement found\n",
      "Epoch 191 completed out of 500. Loss: 0.07061480412951937\n",
      "Improvement found\n",
      "Epoch 196 completed out of 500. Loss: 0.07315475115740355\n",
      "Epoch 201 completed out of 500. Loss: 0.0717694656433423\n",
      "Improvement found\n",
      "Epoch 206 completed out of 500. Loss: 0.06572198413441299\n",
      "Epoch 211 completed out of 500. Loss: 14.086604310779421\n",
      "Epoch 216 completed out of 500. Loss: 0.16113617047631124\n",
      "Epoch 221 completed out of 500. Loss: 0.08825131768685424\n",
      "Epoch 226 completed out of 500. Loss: 0.08487094994018207\n",
      "Epoch 231 completed out of 500. Loss: 0.08626337276712093\n",
      "Epoch 236 completed out of 500. Loss: 0.08062663695578465\n",
      "Epoch 241 completed out of 500. Loss: 0.07577808764865068\n",
      "Epoch 246 completed out of 500. Loss: 0.09419765749023057\n",
      "Epoch 251 completed out of 500. Loss: 0.06744719640541597\n",
      "Improvement found\n",
      "Improvement found\n",
      "Epoch 256 completed out of 500. Loss: 0.06571506790044168\n",
      "Improvement found\n",
      "Epoch 261 completed out of 500. Loss: 0.06562729949553159\n",
      "Epoch 266 completed out of 500. Loss: 3.788486842511702\n",
      "Epoch 271 completed out of 500. Loss: 0.08071986904457162\n",
      "Epoch 276 completed out of 500. Loss: 0.07212248494423079\n",
      "Epoch 281 completed out of 500. Loss: 0.07004215462757202\n",
      "Epoch 286 completed out of 500. Loss: 0.06865575723057304\n",
      "Epoch 291 completed out of 500. Loss: 0.06683029595455992\n",
      "Epoch 296 completed out of 500. Loss: 0.06993956070557772\n",
      "Epoch 301 completed out of 500. Loss: 0.06449670447260303\n",
      "Improvement found\n",
      "Epoch 306 completed out of 500. Loss: 0.06191137359241239\n",
      "Improvement found\n",
      "Improvement found\n",
      "Epoch 311 completed out of 500. Loss: 0.06086552068392237\n",
      "Epoch 316 completed out of 500. Loss: 10.329660301917102\n",
      "Epoch 321 completed out of 500. Loss: 0.08130944558820374\n",
      "Epoch 326 completed out of 500. Loss: 0.09380032580145325\n",
      "Epoch 331 completed out of 500. Loss: 0.07725023844875523\n",
      "Epoch 336 completed out of 500. Loss: 0.06989238202413617\n",
      "Epoch 341 completed out of 500. Loss: 0.06731565102495551\n",
      "Epoch 346 completed out of 500. Loss: 0.06553888007545083\n",
      "Epoch 351 completed out of 500. Loss: 0.06535424604248874\n",
      "Epoch 356 completed out of 500. Loss: 0.07819921257272267\n",
      "Epoch 361 completed out of 500. Loss: 0.06473335638380107\n",
      "Epoch 366 completed out of 500. Loss: 0.06272868238877649\n",
      "Epoch 371 completed out of 500. Loss: 0.06093862307765008\n",
      "Epoch 376 completed out of 500. Loss: 0.06715974950222403\n",
      "Epoch 381 completed out of 500. Loss: 0.16562714357036867\n",
      "Epoch 386 completed out of 500. Loss: 0.08096150068969621\n",
      "Epoch 391 completed out of 500. Loss: 0.07805806612188348\n",
      "Epoch 396 completed out of 500. Loss: 0.07493714871857904\n",
      "Epoch 401 completed out of 500. Loss: 0.07335628749335399\n",
      "Epoch 406 completed out of 500. Loss: 0.07217074394948497\n",
      "Epoch 411 completed out of 500. Loss: 0.07057564967524854\n",
      "Epoch 416 completed out of 500. Loss: 0.07192265250387209\n",
      "Epoch 421 completed out of 500. Loss: 0.0725781477061389\n",
      "Epoch 426 completed out of 500. Loss: 0.07629985994334287\n",
      "Epoch 431 completed out of 500. Loss: 0.06720579942835414\n",
      "Epoch 436 completed out of 500. Loss: 0.061712115462992045\n",
      "Epoch 441 completed out of 500. Loss: 1.7268450142238692\n",
      "Epoch 446 completed out of 500. Loss: 0.06604799358576052\n",
      "Epoch 451 completed out of 500. Loss: 0.06541491726846749\n",
      "Epoch 456 completed out of 500. Loss: 0.06489311910801732\n",
      "Epoch 461 completed out of 500. Loss: 0.06400103042303584\n",
      "Epoch 466 completed out of 500. Loss: 0.06481499528040846\n",
      "Epoch 471 completed out of 500. Loss: 0.06480671365543245\n",
      "Epoch 476 completed out of 500. Loss: 0.06184863287230158\n",
      "Improvement found\n",
      "Epoch 481 completed out of 500. Loss: 0.06521960081206668\n",
      "Epoch 486 completed out of 500. Loss: 0.06177268686952697\n",
      "Improvement found\n",
      "Epoch 491 completed out of 500. Loss: 0.060475437535362\n",
      "Improvement found\n",
      "Epoch 496 completed out of 500. Loss: 0.07304099908666473\n",
      "Improvement found\n",
      "Accuracy on Test-Set: 85.9168% (1879 / 2187). F1 score: 85.7810%.\n"
     ]
    }
   ],
   "source": [
    "cnn(3, epochs = 500, save_model = True, name = \"new\", verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15% complete. Training accuracy: 28.0000%\n",
      "30% complete. Training accuracy: 52.0000%\n",
      "46% complete. Training accuracy: 50.0000%\n",
      "61% complete. Training accuracy: 36.0000%\n",
      "76% complete. Training accuracy: 54.0000%\n",
      "91% complete. Training accuracy: 54.0000%\n",
      "Epoch 1 completed out of 5. Loss: 183.35951507091522\n",
      "15% complete. Training accuracy: 80.0000%\n",
      "30% complete. Training accuracy: 76.0000%\n",
      "46% complete. Training accuracy: 74.0000%\n",
      "61% complete. Training accuracy: 62.0000%\n",
      "76% complete. Training accuracy: 78.0000%\n",
      "91% complete. Training accuracy: 66.0000%\n",
      "Epoch 2 completed out of 5. Loss: 94.74127236008644\n",
      "15% complete. Training accuracy: 88.0000%\n",
      "30% complete. Training accuracy: 82.0000%\n",
      "46% complete. Training accuracy: 78.0000%\n",
      "61% complete. Training accuracy: 72.0000%\n",
      "76% complete. Training accuracy: 80.0000%\n",
      "91% complete. Training accuracy: 72.0000%\n",
      "Epoch 3 completed out of 5. Loss: 73.40512526035309\n",
      "15% complete. Training accuracy: 86.0000%\n",
      "30% complete. Training accuracy: 84.0000%\n",
      "46% complete. Training accuracy: 80.0000%\n",
      "61% complete. Training accuracy: 80.0000%\n",
      "76% complete. Training accuracy: 86.0000%\n",
      "91% complete. Training accuracy: 76.0000%\n",
      "Epoch 4 completed out of 5. Loss: 61.50619074702263\n",
      "15% complete. Training accuracy: 84.0000%\n",
      "30% complete. Training accuracy: 88.0000%\n",
      "46% complete. Training accuracy: 86.0000%\n",
      "61% complete. Training accuracy: 82.0000%\n",
      "76% complete. Training accuracy: 92.0000%\n",
      "91% complete. Training accuracy: 82.0000%\n",
      "Epoch 5 completed out of 5. Loss: 52.633724339306355\n",
      "Accuracy on Test-Set: 80.1097% (1752 / 2187). F1 score: 80.1356%.\n"
     ]
    }
   ],
   "source": [
    "cnn(3, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed out of 200. Loss: 202.0862513780594\n",
      "Epoch 6 completed out of 200. Loss: 115.51690223813057\n",
      "Epoch 11 completed out of 200. Loss: 66.47385893017054\n",
      "Epoch 16 completed out of 200. Loss: 45.45010309293866\n",
      "Epoch 21 completed out of 200. Loss: 34.66224016435444\n",
      "Epoch 26 completed out of 200. Loss: 32.064170776167884\n",
      "Epoch 31 completed out of 200. Loss: 29.244369554537116\n",
      "Epoch 36 completed out of 200. Loss: 23.306455018722772\n",
      "Epoch 41 completed out of 200. Loss: 20.851939070271328\n",
      "Epoch 46 completed out of 200. Loss: 19.72495153475029\n",
      "Epoch 51 completed out of 200. Loss: 19.76574745295966\n",
      "Epoch 56 completed out of 200. Loss: 17.08873333502561\n",
      "Epoch 61 completed out of 200. Loss: 17.702685355587164\n",
      "Epoch 66 completed out of 200. Loss: 14.463029035883665\n",
      "Epoch 71 completed out of 200. Loss: 14.379956649703672\n",
      "Epoch 76 completed out of 200. Loss: 13.118327643955126\n",
      "Epoch 81 completed out of 200. Loss: 15.130038704551794\n",
      "Epoch 86 completed out of 200. Loss: 10.054874070485795\n",
      "Epoch 91 completed out of 200. Loss: 9.54907908079489\n",
      "Epoch 96 completed out of 200. Loss: 13.85449634491738\n",
      "Epoch 101 completed out of 200. Loss: 9.126988005322431\n",
      "Epoch 106 completed out of 200. Loss: 8.578800897830718\n",
      "Epoch 111 completed out of 200. Loss: 10.225553461587793\n",
      "Epoch 116 completed out of 200. Loss: 10.758084648871545\n",
      "Epoch 121 completed out of 200. Loss: 7.674742195564736\n",
      "Epoch 126 completed out of 200. Loss: 7.5398007254189\n",
      "Epoch 131 completed out of 200. Loss: 10.459096564307401\n",
      "Epoch 136 completed out of 200. Loss: 9.200440418661856\n",
      "Epoch 141 completed out of 200. Loss: 7.692184680316132\n",
      "Epoch 146 completed out of 200. Loss: 6.803135996153287\n",
      "Epoch 151 completed out of 200. Loss: 8.380421452710415\n",
      "Epoch 156 completed out of 200. Loss: 10.29754971897637\n",
      "Epoch 161 completed out of 200. Loss: 6.118346273468333\n",
      "Epoch 166 completed out of 200. Loss: 5.601746256199145\n",
      "Epoch 171 completed out of 200. Loss: 5.338927085891555\n",
      "Epoch 176 completed out of 200. Loss: 5.159699070260103\n",
      "Epoch 181 completed out of 200. Loss: 14.033902758428098\n",
      "Epoch 186 completed out of 200. Loss: 5.079069092429137\n",
      "Epoch 191 completed out of 200. Loss: 4.7817662578218005\n",
      "Epoch 196 completed out of 200. Loss: 4.682203603968446\n",
      "Accuracy on Test-Set: 54.6868% (1196 / 2187). F1 score: 54.3897%.\n"
     ]
    }
   ],
   "source": [
    "cnn(0, epochs = 200, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed out of 200. Loss: 261.4665811061859\n",
      "Epoch 6 completed out of 200. Loss: 86.70396772027016\n",
      "Epoch 11 completed out of 200. Loss: 54.996858447790146\n",
      "Epoch 16 completed out of 200. Loss: 36.51385881751776\n",
      "Epoch 21 completed out of 200. Loss: 20.463196581229568\n",
      "Epoch 26 completed out of 200. Loss: 11.835750481288414\n",
      "Epoch 31 completed out of 200. Loss: 7.555114217335358\n",
      "Epoch 36 completed out of 200. Loss: 6.053574820281938\n",
      "Epoch 41 completed out of 200. Loss: 1.698956900670055\n",
      "Epoch 46 completed out of 200. Loss: 2.229933993314262\n",
      "Epoch 51 completed out of 200. Loss: 1.9789735964732245\n",
      "Epoch 56 completed out of 200. Loss: 0.5888542545526434\n",
      "Epoch 61 completed out of 200. Loss: 9.067863720178138\n",
      "Epoch 66 completed out of 200. Loss: 0.3728846343983605\n",
      "Epoch 71 completed out of 200. Loss: 0.7449031285023011\n",
      "Epoch 76 completed out of 200. Loss: 0.4591764505548781\n",
      "Epoch 81 completed out of 200. Loss: 0.4602456727811841\n",
      "Epoch 86 completed out of 200. Loss: 0.38084018102836126\n",
      "Epoch 91 completed out of 200. Loss: 0.2816165537510642\n",
      "Epoch 96 completed out of 200. Loss: 0.21727799350765054\n",
      "Epoch 101 completed out of 200. Loss: 1.7602014320436865\n",
      "Epoch 106 completed out of 200. Loss: 0.21969394731422653\n",
      "Epoch 111 completed out of 200. Loss: 0.20070034025593486\n",
      "Epoch 116 completed out of 200. Loss: 0.171123050404276\n",
      "Epoch 121 completed out of 200. Loss: 0.14970476023563606\n",
      "Epoch 126 completed out of 200. Loss: 0.14430977153642743\n",
      "Epoch 131 completed out of 200. Loss: 0.14860653611640373\n",
      "Epoch 136 completed out of 200. Loss: 5.7436585206887685\n",
      "Epoch 141 completed out of 200. Loss: 0.18642282729160797\n",
      "Epoch 146 completed out of 200. Loss: 0.166646473903711\n",
      "Epoch 151 completed out of 200. Loss: 0.15898458201536414\n",
      "Epoch 156 completed out of 200. Loss: 0.16722683486659662\n",
      "Epoch 161 completed out of 200. Loss: 0.13382199126499472\n",
      "Epoch 166 completed out of 200. Loss: 0.14342394172263084\n",
      "Epoch 171 completed out of 200. Loss: 0.11136952540482525\n",
      "Epoch 176 completed out of 200. Loss: 2.250115102622658\n",
      "Epoch 181 completed out of 200. Loss: 0.16740065973863238\n",
      "Epoch 186 completed out of 200. Loss: 0.13656118138169404\n",
      "Epoch 191 completed out of 200. Loss: 0.13165772682987154\n",
      "Epoch 196 completed out of 200. Loss: 0.11943835555030091\n",
      "Accuracy on Test-Set: 79.0581% (1729 / 2187). F1 score: 78.7538%.\n"
     ]
    }
   ],
   "source": [
    "cnn(1, epochs = 200, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed out of 200. Loss: 148.78365647792816\n",
      "Epoch 6 completed out of 200. Loss: 38.36873853765428\n",
      "Epoch 11 completed out of 200. Loss: 19.13821093412116\n",
      "Epoch 16 completed out of 200. Loss: 8.041380075592315\n",
      "Epoch 21 completed out of 200. Loss: 4.212144990545312\n",
      "Epoch 26 completed out of 200. Loss: 4.209489224025447\n",
      "Epoch 31 completed out of 200. Loss: 3.2927138511968224\n",
      "Epoch 36 completed out of 200. Loss: 1.9552249196240155\n",
      "Epoch 41 completed out of 200. Loss: 1.6141524005670362\n",
      "Epoch 46 completed out of 200. Loss: 1.408691834185447\n",
      "Epoch 51 completed out of 200. Loss: 6.774413686505795\n",
      "Epoch 56 completed out of 200. Loss: 1.4447593315501308\n",
      "Epoch 61 completed out of 200. Loss: 1.2143592613838905\n",
      "Epoch 66 completed out of 200. Loss: 1.1563331105364796\n",
      "Epoch 71 completed out of 200. Loss: 1.1527110767475008\n",
      "Epoch 76 completed out of 200. Loss: 1.2379798593074156\n",
      "Epoch 81 completed out of 200. Loss: 1.2222909873152616\n",
      "Epoch 86 completed out of 200. Loss: 1.1153911849015685\n",
      "Epoch 91 completed out of 200. Loss: 1.0720008499228726\n",
      "Epoch 96 completed out of 200. Loss: 1.1736615285389007\n",
      "Epoch 101 completed out of 200. Loss: 1.306811127990386\n",
      "Epoch 106 completed out of 200. Loss: 1.4536926289665644\n",
      "Epoch 111 completed out of 200. Loss: 1.0431070545910188\n",
      "Epoch 116 completed out of 200. Loss: 0.9679253867883517\n",
      "Epoch 121 completed out of 200. Loss: 0.9528925726183388\n",
      "Epoch 126 completed out of 200. Loss: 0.9741493786917204\n",
      "Epoch 131 completed out of 200. Loss: 1.0194153807735802\n",
      "Epoch 136 completed out of 200. Loss: 12.28995135428704\n",
      "Epoch 141 completed out of 200. Loss: 1.0225504675505306\n",
      "Epoch 146 completed out of 200. Loss: 0.9474940822329074\n",
      "Epoch 151 completed out of 200. Loss: 0.9841557690213278\n",
      "Epoch 156 completed out of 200. Loss: 0.8953096120489477\n",
      "Epoch 161 completed out of 200. Loss: 0.8461078632651606\n",
      "Epoch 166 completed out of 200. Loss: 0.822114765326134\n",
      "Epoch 171 completed out of 200. Loss: 0.8064145905740361\n",
      "Epoch 176 completed out of 200. Loss: 0.7895416432780848\n",
      "Epoch 181 completed out of 200. Loss: 11.677558505660272\n",
      "Epoch 186 completed out of 200. Loss: 0.9239426134420725\n",
      "Epoch 191 completed out of 200. Loss: 0.8405707624478396\n",
      "Epoch 196 completed out of 200. Loss: 0.8476034511482311\n",
      "Accuracy on Test-Set: 83.3562% (1823 / 2187). F1 score: 82.9633%.\n"
     ]
    }
   ],
   "source": [
    "cnn(2, epochs = 200, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed out of 200. Loss: 215.71210664510727\n",
      "Epoch 6 completed out of 200. Loss: 64.89219778776169\n",
      "Epoch 11 completed out of 200. Loss: 33.605582505464554\n",
      "Epoch 16 completed out of 200. Loss: 15.370372039149515\n",
      "Epoch 21 completed out of 200. Loss: 5.088374967730488\n",
      "Epoch 26 completed out of 200. Loss: 2.2736340897681657\n",
      "Epoch 31 completed out of 200. Loss: 1.182904278381102\n",
      "Epoch 36 completed out of 200. Loss: 1.1278397807636793\n",
      "Epoch 41 completed out of 200. Loss: 0.7087203543109126\n",
      "Epoch 46 completed out of 200. Loss: 0.9084192884402\n",
      "Epoch 51 completed out of 200. Loss: 1.540683937506401\n",
      "Epoch 56 completed out of 200. Loss: 6.010517307469854\n",
      "Epoch 61 completed out of 200. Loss: 0.4234687371727546\n",
      "Epoch 66 completed out of 200. Loss: 0.2801914910436949\n",
      "Epoch 71 completed out of 200. Loss: 0.2066887490984186\n",
      "Epoch 76 completed out of 200. Loss: 0.1634776263774711\n",
      "Epoch 81 completed out of 200. Loss: 0.18885761284536784\n",
      "Epoch 86 completed out of 200. Loss: 0.48213239250253537\n",
      "Epoch 91 completed out of 200. Loss: 0.1415122051803337\n",
      "Epoch 96 completed out of 200. Loss: 0.1255019384946081\n",
      "Epoch 101 completed out of 200. Loss: 0.10606330061625613\n",
      "Epoch 106 completed out of 200. Loss: 0.09539849492188068\n",
      "Epoch 111 completed out of 200. Loss: 0.09145053415272741\n",
      "Epoch 116 completed out of 200. Loss: 14.262244060132616\n",
      "Epoch 121 completed out of 200. Loss: 0.1422584242445737\n",
      "Epoch 126 completed out of 200. Loss: 0.09749840847848645\n",
      "Epoch 131 completed out of 200. Loss: 0.09025438949311138\n",
      "Epoch 136 completed out of 200. Loss: 0.07735099798196643\n",
      "Epoch 141 completed out of 200. Loss: 0.10491366345172537\n",
      "Epoch 146 completed out of 200. Loss: 0.06952221216567978\n",
      "Epoch 151 completed out of 200. Loss: 0.12967484164050802\n",
      "Epoch 156 completed out of 200. Loss: 0.12421299576499223\n",
      "Epoch 161 completed out of 200. Loss: 0.11035239153443399\n",
      "Epoch 166 completed out of 200. Loss: 0.09734718430581779\n",
      "Epoch 171 completed out of 200. Loss: 0.08526496085448798\n",
      "Epoch 176 completed out of 200. Loss: 0.08054642357228659\n",
      "Epoch 181 completed out of 200. Loss: 0.08900592980756983\n",
      "Epoch 186 completed out of 200. Loss: 0.11082141018755465\n",
      "Epoch 191 completed out of 200. Loss: 0.0847084909708542\n",
      "Epoch 196 completed out of 200. Loss: 1.5902251732327386\n",
      "Accuracy on Test-Set: 84.4993% (1848 / 2187). F1 score: 84.3580%.\n"
     ]
    }
   ],
   "source": [
    "cnn(3, epochs = 200, verbose = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
